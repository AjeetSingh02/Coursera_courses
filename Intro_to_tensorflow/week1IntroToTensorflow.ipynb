{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week1IntroToTensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NNOXiNS6hz1L",
        "4kEaWI0ii2gC",
        "t9EwgAMJls2G",
        "Dd4ucN0dpdkS"
      ],
      "authorship_tag": "ABX9TyOSyhpoNKMOelK57Lln5KgM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Courses/blob/master/Intro_to_tensorflow/week1IntroToTensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7xFoJ8FhkrO",
        "colab_type": "code",
        "outputId": "7fc4aaba-65d1-4c1b-9136-6bb8320d71c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNOXiNS6hz1L",
        "colab_type": "text"
      },
      "source": [
        "# Lazy Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQRFri8Nh2jR",
        "colab_type": "code",
        "outputId": "8c26c190-bc0f-474c-a8a4-0d4b7af48e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = tf.constant([5, 6, 2])\n",
        "b = tf.constant([2, 1, 2])\n",
        "c = tf.add(a, b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Add:0\", shape=(3,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZnC0mn2iNB7",
        "colab_type": "text"
      },
      "source": [
        "Here the \"c\" is a 1D tensor but it is not the sum of \"a\" and \"b\". At current state is not evaluated. This is lazy evaluation. Until explicitlly told the evaluation will not occur. For evaluation we will do this: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjN88O2_ikZA",
        "colab_type": "code",
        "outputId": "dac599ca-603b-447f-a196-fbc2adb83906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(c))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 7 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meNcYpXFisKq",
        "colab_type": "text"
      },
      "source": [
        "Now we can see the results. We have made a instance of Session and the evaluated using run command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kEaWI0ii2gC",
        "colab_type": "text"
      },
      "source": [
        "# Graph and Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-XsgNdIkFPp",
        "colab_type": "text"
      },
      "source": [
        "The Directed Acyclic Graph, the DAG in TensorFlow, is like any graph. It consists of edges and nodes. The edges represent data, they represent tensors, which as we now know, are n-dimensional arrays. The nodes represent TensorFlow operations on those tensors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2JsbNE-kGVb",
        "colab_type": "text"
      },
      "source": [
        "A TensorFlow DAG consists of tensors and operations on those tensors. \n",
        "\n",
        "Whatever calculation happens in TensorFlow, it is represented as Directed Ascyclic Graph (DAG) and only after we explicitly tells to run the results are calculated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7ACY1QTkOZw",
        "colab_type": "text"
      },
      "source": [
        "**why does TensorFlow do lazy evaluation?**\n",
        "\n",
        "It's because lazy evaluation allows for a lot of flexibility and optimization when you're running the graph. \n",
        "\n",
        "TensorFlow can now process the graph, compile it, inserts **send** and **receive** nodes in the middle of the DAG, also that it can be remotely executed. \n",
        "\n",
        "Tensorflow can assign different parts of the DAG to different devices, depending on whether it's I/O bound, or whether it's going to require GPU capabilities. \n",
        "\n",
        "While the graph is being processed, TensorFlow can add quantization or data types, it can add debug nodes, it can create summaries to write values out, so tensor can read them besides computation like add, matmul, constants, variables all of these are ops and TensorFlow can work with them. \n",
        "\n",
        "When the graph is being compiled, TensorFlow can take two ops and fuse them to improve performance. For example, you may have two consecutive add nodes, and TensorFlow can fuse them into a single one.\n",
        "\n",
        "TensorFlow's XLA compiler can use the information into a Directed Acyclic Graph to generate faster code. So, that's one aspect of why you want to use a DAG for optimization. \n",
        "\n",
        "But the most exciting part is that the DAG can be remotely executed and assigned to devices. And that's where the benefits of the DAG approach become very evident. \n",
        "\n",
        "By using explicit edges to represent dependencies between operations, it's easy for the system to identify operations that can execute in parallel. And by using explicit edges to represent the values that flow between operations, it's possible for TensorFLow to partition your program across multiple devices; CPUs, GPUs, TPUs, etc that are attached even to different machines. \n",
        "TensorFlow inserts the necessary communication and coordination between these devices.\n",
        "\n",
        "Several parts of the graph can be on different devices, it doesn't matter whether it's GPU or different computers. So, one key benefit of this model to be able to distribute computation across many machines, and many types of machines, comes because of the DAG. We just write Python code and let the TensorFlow execution system optimize and distribute the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyJoz5j9lYzF",
        "colab_type": "text"
      },
      "source": [
        "**Session Class**\n",
        "\n",
        "The session class represents the connection between the Python program that we write, and the C++ runtime. \n",
        "\n",
        "The session object provides access to the devices on the local machine, and to remote devices using the distributor TensorFlow runtime. It also caches information about the graph, so, the same computation can be run multiple times. \n",
        "\n",
        "As we saw, we execute TensorFlow graphs by calling run on a tf session, and when we do that, we specify a tensor that we want to evaluate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sp_SjbQlqCk",
        "colab_type": "text"
      },
      "source": [
        "So, in the code example above, we defined two data tensors **a** and **b**. They're constants, they are 1D tensors. The tensor **c** is a result of invoking **tf.add** on **a** and **b**. When we want to evaluate, we call **session.run** on **c**. Session here **sess**, is an instance of **tf** session, and the **with** statement in Python, is how we can ensure that the session is automatically closed when we are done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9EwgAMJls2G",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating a Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU6yIvhrmtMN",
        "colab_type": "text"
      },
      "source": [
        "You can call **sess.run(z)** or you can call **z.eval** to evaluate **z** in the context of the default session. \n",
        "\n",
        "**z.eval** is just a shortcut, and you will often see it in the code. It is the same as calling run on the default session. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQRJSDH5ncj7",
        "colab_type": "code",
        "outputId": "d957c5e7-75e6-46e7-90fe-45a9da47037e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "y = tf.constant([5, 6, 3])\n",
        "z = tf.add(x, y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(z.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 8 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEIxy6asn73R",
        "colab_type": "text"
      },
      "source": [
        "While you can call **session.run** and passing a single answer, you can also pass in a list of tensors to evaluate. \n",
        "\n",
        "TensorFlow will figure out which parts of the graph it needs to evaluate and carry out the evaluation. \n",
        "\n",
        "For each input tensor, there is a corresponding numPy array in the output. \n",
        "\n",
        "Since we passed in **z** and **z3**, you get back two numPy arrays that I'm calling **a1** and **a3**. \n",
        "\n",
        "Notice that this code also shows that you don't need to write out **tf.Add( x,y)**. You can simply say **x** plus **y**, because the common arithmetic operations, they're overloaded. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT1w7TsVn_UT",
        "colab_type": "code",
        "outputId": "28881499-337c-43d0-c647-b4a8e27f619e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "y = tf.constant([5, 6, 3])\n",
        "z1 = tf.add(x, y)\n",
        "z2 = x + y\n",
        "z3 = z2 - z1\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    # For each input tensor, there is a corresponding numPy array in the output.\n",
        "    a1, a3 = sess.run([z1, z3])\n",
        "    \n",
        "    print(a1)\n",
        "    print(a3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 8 6]\n",
            "[-1  4  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7IFWfRNnc8q",
        "colab_type": "text"
      },
      "source": [
        "I briefly mentioned **tf.eager** earlier. Commonly, TensorFlow programs use the lazy evaluation, and this is what I recommend when you're writing production code. \n",
        "\n",
        "However, when you're developing, when you're debugging, it can sometimes be convenient to have the code executed immediately instead of lazily. So here, I'm showing how to use **tf.eager**. \n",
        "\n",
        "You import tf eager and enable eager execution. But make sure to do this only once. Typically you do it at the start of your code. \n",
        "\n",
        "So here, I'm creating two tensors **x** and **y**, and printing out **x** minus **y**. \n",
        "\n",
        "If we are not an eager mode, what would get printed out? Just the debug output of the tensor. This would have included a system assigned a unique name for the node and the Dagg and the shape, and the datatype of the value that will show up when the daggers run. \n",
        "\n",
        "But because we are in eager mode, we don't have to wait for session that run to get the actual result of the subtraction. That's why, when I do x minus y, you see the list 2, 3, 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJpPMj6o7nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.contrib.eager.python import tfe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG30Q2TlpHPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't run\n",
        "# It will throw ValueError: tf.enable_eager_execution must be called at program startup here.\n",
        "tfe.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoG2ODt0pNGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant([3, 5, 7])\n",
        "y = tf.constant([1, 2, 3])\n",
        "print(x - y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd4ucN0dpdkS",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing a Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBgO8vSQieK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant([3, 5, 7], name=\"x\")\n",
        "y = tf.constant([1, 2, 3], name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YQV3EdaiogR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z1 = tf.add(x, y, name=\"z1\")\n",
        "z2 = x * y\n",
        "z3 = z2 - z1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fetCpnM0i6wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    with tf.summary.FileWriter('summaries', sess.graph) as writer:\n",
        "        a1, a3 = sess.run([z1, z3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YK2lnoIi0CI",
        "colab_type": "code",
        "outputId": "67ec5875-8bb8-49b4-d47b-f37ebda4c517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! ls summaries"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1582236612.580400288a05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ41gwdBkDxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "! pip install datalab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGxeR081j0Cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.datalab.ml import TensorBoard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ILEJil-kNeq",
        "colab_type": "code",
        "outputId": "40a644de-b907-4e62-87a1-01c2b9b0e786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "TensorBoard().start('./summaries')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p>TensorBoard was started successfully with pid 664. Click <a href=\"/_proxy/52013/\" target=\"_blank\">here</a> to access it.</p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p-ostmhwZ2y",
        "colab_type": "text"
      },
      "source": [
        "# Variables and Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZMI4r7dwf8T",
        "colab_type": "code",
        "outputId": "211c30e5-8235-40bb-8bf8-1587e9e046e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Shape of Tensors\n",
        "x = tf.constant(3)\n",
        "print(\"0D \", x)\n",
        "\n",
        "x = tf.constant([1,2,3])\n",
        "print(\"1D \", x)\n",
        "\n",
        "x = tf.constant([[1,2,3], [2,3,4]])\n",
        "print(\"2D \", x)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0D  Tensor(\"Const_7:0\", shape=(), dtype=int32)\n",
            "1D  Tensor(\"Const_8:0\", shape=(3,), dtype=int32)\n",
            "2D  Tensor(\"Const_9:0\", shape=(2, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMI2PWFvwnoF",
        "colab_type": "text"
      },
      "source": [
        "We can create higher dimensional Tesors as above or we can use **stack**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXiF0M7YxdA0",
        "colab_type": "code",
        "outputId": "0321fa41-fa2b-4ba2-f0ed-56ce46b0a33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "x1 = tf.constant([1,2,3])\n",
        "\n",
        "x2 = tf.stack([x1, x1])\n",
        "print(\"Two 1D Tensors of shape (3,) stacked one above other results in 2D Tensor of shape (2,3): \", x2)\n",
        "\n",
        "x3 = tf.stack([x2, x2, x2, x2])\n",
        "print(\"Four 2D Tensors of shape(2,3) stacked one above other results in 3D Tensor of shape (4, 2, 3): \", x3)\n",
        "\n",
        "x4 = tf.stack([x2, x2])\n",
        "print(\"Two 3D Tensors of shape (4, 2, 3) stacked one above other results in 4D Tensor of shape (2, 4, 2, 3)\", x4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Two 1D Tensors of shape (3,) stacked one above other results in 2D Tensor of shape (2,3):  Tensor(\"stack_3:0\", shape=(2, 3), dtype=int32)\n",
            "Four 2D Tensors of shape(2,3) stacked one above other results in 3D Tensor of shape (4, 2, 3):  Tensor(\"stack_4:0\", shape=(4, 2, 3), dtype=int32)\n",
            "Two 3D Tensors of shape (4, 2, 3) stacked one above other results in 4D Tensor of shape (2, 4, 2, 3) Tensor(\"stack_5:0\", shape=(2, 2, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g0VKA0I_1tM",
        "colab_type": "text"
      },
      "source": [
        "**Slicing on Tensors**\n",
        "\n",
        "Similar to python Slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-0Jp2EvAfYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant([[3, 5, 7],\n",
        "                 [4, 8, 7]])\n",
        "y = x[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssf3z4aKArq2",
        "colab_type": "code",
        "outputId": "74950dba-5ad7-461e-99db-06b07f4ba80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    print(y.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj9366v_BzGL",
        "colab_type": "text"
      },
      "source": [
        "**Reshaping on Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I45de0anB1UQ",
        "colab_type": "code",
        "outputId": "9133e191-132a-4536-f9a4-a98dc9cfd4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "x = tf.constant([[3, 5, 7],\n",
        "                 [4, 8, 7]])\n",
        "y = tf.reshape(x, [3, 2])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(y.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 5]\n",
            " [7 4]\n",
            " [8 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieeaScCMB1fi",
        "colab_type": "text"
      },
      "source": [
        "Above in the reshaping you can see that since the desired shape is [3,2] that is 3 rows 2 columns. So 1st two elements are choosen then next 2 and so on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_DhSt6C6ogI",
        "colab_type": "text"
      },
      "source": [
        "**Variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPyAufGZB1sk",
        "colab_type": "text"
      },
      "source": [
        "A variable is a tensor whose value is initialized and then the value gets changed as a program runs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qHE-7hm6tPE",
        "colab_type": "text"
      },
      "source": [
        "We will understand using the below code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k45D46soB14L",
        "colab_type": "code",
        "outputId": "d2820683-daab-4c56-c874-941259e3bcc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "def forward_pass(w, x):\n",
        "    return tf.matmul(w, x)\n",
        "\n",
        "\n",
        "def train_loop(x, niter=5):\n",
        "    with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
        "        w = tf.get_variable(\"weights\",\n",
        "                            shape=(1,2),    # 1 * 2 Matrix\n",
        "                            initializer = tf.truncated_normal_initializer(),\n",
        "                            trainable=True\n",
        "                            )\n",
        "    preds = []\n",
        "    for k in range(niter):\n",
        "        preds.append(forward_pass(w, x))\n",
        "        w = w + 0.1     # Kind of gradient update\n",
        "    return preds\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    preds = train_loop(tf.constant([[3.2, 5.1, 7.2], [4.3, 6.2, 8.3]]))     # 2 * 3 Matrix\n",
        "    tf.global_variables_initializer().run()\n",
        "    for i in range(len(preds)):\n",
        "        print(f\"{i}: {preds[i].eval()}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: [[ -5.7171655  -8.716917  -12.032432 ]]\n",
            "1: [[ -4.967165   -7.5869164 -10.482431 ]]\n",
            "2: [[-4.2171655 -6.456917  -8.932431 ]]\n",
            "3: [[-3.4671652 -5.3269167 -7.3824315]]\n",
            "4: [[-2.7171652 -4.1969166 -5.8324313]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgeA2xtdB2DL",
        "colab_type": "text"
      },
      "source": [
        "Let's take a close look at this example. \n",
        "\n",
        "I have a function called **forward_pass**, which takes two parameters, **w** and **x**, and multiplies them. Well, it's a matrix multiply because these are **tensors**.\n",
        "\n",
        "In my train loop function, I basically create the tensor **w** except that **w** is not a constant like the tensors that we've been looking at so far. **W** is a variable. \n",
        "\n",
        "It has a **name**, **weights**. Its shape is **(1,2)**, which means that it has one row and two columns. It's a 1 by 2 matrix. And when **w** is initialized, we are not initializing it here because remember, TensorFlow is a lazy evaluation framework and so we are only building the graph. We're not yet running it. \n",
        "\n",
        "When w is initialized, it will be initialized by a **truncated normal initializer**. \n",
        "\n",
        "This is a very common initializer that you will see in TensorFlow neural network programs. It initializes a variable to random numbers, but these random numbers are not uniformly distributed. Instead, they have a Gaussian normal distribution with zero mean and unit variants. But Gaussian normal has a very long tail and you might get extreme outliers. It's very unlikely but it could happen. So, what a truncated normal does, well, it kind of truncates things at sum multiplication of sigma. \n",
        "\n",
        "Finally, we say that the variable **w** is **trainable**. A trainable variable is a variable that can be changed during training. The point of a variable of course is to be able to change it so most variables will be trainable. But every once in a while, we'll talk about this when we talk about model size reduction and then we talk about transferred learning. Every once in a while, it can be helpful to freeze a graph to make it such that the variables are not changed. This Boolean flag lets us do that. \n",
        "\n",
        "Notice that I'm calling **tf.get_variable** to create **w**. Now, you might see TensorFlow code that directly creates a variable by calling the **tf.variable** constructor. **Calling the constructor directly is not recommended**. \n",
        "\n",
        "**Use tf.get_variable** because, as we'll see in course 9, it can be helpful to be able to reuse variables or create them afresh depending on different situations and using **tf.get_variable** let's us do so. So, I recommend that you get into the habit of using tf.get_variable. \n",
        "\n",
        "So, we then run the forward pass five times and store the result of the matrix multiply at each iteration. So, after we do the product, we change the weight. Here we are adding **0.1** to it. This is like a gradient update. In reality, of course, in gradient update, we will choose what weights to change and how to change them. But here, for just demo purposes, I'll just add 0.1 to the weights each time. \n",
        "\n",
        "Now, from the session, we call train loop by passing in **x**. The **x is a 2 by 3 matrix**. So in the forward pass, we multiply **w** by this **x**. **W** is a 1 by 2 matrix. Multiplying a 1 by 2 by 2 by 3 gives us a 1 by 3 matrix. \n",
        "\n",
        "So, at this point, the graph is done but we still need to initialize the variables. That's the run stage. We typically just initialized all the variables in the graph all at once by running the **global variables initializer**. \n",
        "\n",
        "So, when we now look at the value of the product after each step of the loop, we notice that the 1 by 3 matrix each time is different as you would expect. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38EHAaOXB2ZV",
        "colab_type": "text"
      },
      "source": [
        "**So, let's summarize what we have just learned.** \n",
        "\n",
        "**1.** create a variable by calling **get variable** \n",
        "\n",
        "Well, I skipped over one line of code when I went through it, the **scope piece**. **tf.variable_scope**. When you create a variable, you can specify the scope. That's where I'm telling TensorFlow to reuse the variable each time instead of creating a new variable each time. I'm calling train loop only once so it doesn't matter here, but if I were to call train loop again, the weights would resume from where they left off. We will not create a new variable. We would reuse it. \n",
        "\n",
        "**2.** Second thing that you're learning here is that when you create a variable, you have to decide on how to initialize a variable. In neural network training, random normal with truncation is a typical choice. \n",
        "\n",
        "**3.** Use the variable just like any other tensor when building the graph.\n",
        "\n",
        "**4.** In your session, remember to initialize the variable. Usually, you will initialize all the variables together by calling the **global variables initializer**. \n",
        "\n",
        "**5.** And after the variables are initialized, you can evaluate any tensor that you want to evaluate. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82V-KXTrABaC",
        "colab_type": "text"
      },
      "source": [
        "**Placeholders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwVzYx7S_-9B",
        "colab_type": "text"
      },
      "source": [
        "In this example, we are calling the train loop with the **x**, but the **x** is a **constant**. How realistic is that? Do you hardcode input values into your programs? **NO**\n",
        "\n",
        "**Placeholders allow you to feed in values into the graph.** \n",
        "\n",
        "For example, you can read values from a text file into a Python list and then feed that list into the TensorFlow graph. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zj3pa0cAX2T",
        "colab_type": "code",
        "outputId": "92bdbe8f-7271-4108-e0fa-2985fb5215af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "a = tf.placeholder(\"float\", None)\n",
        "b = a * 4\n",
        "print(a)\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(b, feed_dict={a: [1,2,3]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", dtype=float32)\n",
            "[ 4.  8. 12.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3mb8lOsAXEn",
        "colab_type": "text"
      },
      "source": [
        "So, here, **a** is a **placeholder**. It will hold a scalar. **b** is **a** multiplied by **4**. If you print **a**, you will get the debug output of a tensor. You will learn that this particular tensor is a placeholder that expects floating point numbers to be fed into it. \n",
        "\n",
        "If you now want to evaluate **b**, you can adjust this **session.run(b)**. You have to feed in values for the placeholders that **b** depends upon. So in this case, you have to pass in a list or a numpy array of numbers for the placeholder **a**, and you do this using a **feed dict**, a dictionary. The key is a placeholder, in this case, **a**. The value is a list of numpy array. And in this case, it's **[1,2,3]**. So that's what we feed in, and so when **b** is evaluated, you get the value of **a** multiply by **4**, so we get **[4,8,12]**."
      ]
    }
  ]
}